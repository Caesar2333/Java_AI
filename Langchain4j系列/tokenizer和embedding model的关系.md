# ä¸‹é¢é—®é¢˜çš„è§£ç­”

>ï¼ˆ1ï¼‰<dependency>    <groupId>dev.langchain4j</groupId>    <artifactId>langchain4j-easy-rag</artifactId>    <version>1.0.1-beta6</version> </dependency> 
>
>æˆ‘è¯´çš„æ˜¯è¿™ä¸ªeasy-rag å’Œé»˜è®¤çš„tokenizer è¿™æ ·ä¼šä¸ä¼šå‡ºé—®é¢˜ å¦‚æœç›´æ¥ä½¿ç”¨é»˜è®¤çš„è¯
>
>ï¼ˆ2ï¼‰è¿˜æœ‰è¿™ä¸ªåé¢ç”¨åˆ°çš„é˜¿é‡Œç™¾ç‚¼çš„ text-embedding-v3 è¿™ä¸ªæ¨¡å‹ï¼Œå¦‚æœç”¨é»˜è®¤çš„tokenizerï¼Œtokenè¶…æ ‡å°±ä¸è¯´ï¼Œä»–å¦ˆçš„æ¨¡å‹èƒ½ä¸èƒ½è¯†åˆ«æ˜¯å¦å¤–ä¸€å›äº‹
>
>ï¼ˆ3ï¼‰è€Œä¸”æˆ‘æœ‰ä¸€ä¸ªç–‘é—®ï¼šè¿™ä¸ªspliter åˆ†æ®µæ‹†å¼€äº†ä¹‹åï¼Œè¿˜è¦ç»è¿‡tokenizer ç»™åˆ†æˆtoken åœ¨å–‚ç»™embeding model å»æŠ½è±¡æˆä¸ºå‘é‡å—ï¼Ÿï¼Ÿé‚£å²‚ä¸æ˜¯å¯èƒ½ä¸€æ®µåˆ†æˆä¸¤éƒ¨åˆ† token??



ä½ è¿™ç»„é—®é¢˜æ˜¯å¯¹ **RAG çš„æ–‡æœ¬åˆ‡åˆ†æœºåˆ¶ã€tokenizer åŒ¹é…ç­–ç•¥ã€embedding æ¨¡å‹å¤„ç†æµç¨‹** çš„å…¨é“¾è·¯æ·±æŒ–ï¼Œæˆ‘æ˜ç¡®å‘Šè¯‰ä½ ï¼š

> âœ… ä½ å®Œå…¨æ­£ç¡®åœ°æŒ‡å‡ºäº† **â€œé»˜è®¤ tokenizer + éé»˜è®¤ embedding modelâ€ ä¼šå¯¼è‡´ä¸¥é‡é—®é¢˜**ï¼Œè€Œä¸”è¿™ç§é”™è¯¯**ä¸ä¼šæŠ¥é”™ä½†ç»“æœå˜å·®**ï¼Œéå¸¸éšè”½ã€‚

æˆ‘æŒ‰é¡ºåºæŠŠè¿™å‡ ä¸ªé—®é¢˜è®²é€ï¼š

## â“1. ä½ ç”¨äº†è¿™ä¸ªä¾èµ–ï¼š

```
<artifactId>langchain4j-easy-rag</artifactId>
```

ç„¶åé—®ï¼š

### â“å¦‚æœæˆ‘ä¸è®¾ç½® `tokenCountEstimator`ï¼Œç›´æ¥é»˜è®¤ç”¨ `easy-rag`ï¼Œä¼šä¸ä¼šå‡ºé—®é¢˜ï¼Ÿ

âœ… **ä¼šå‡ºé—®é¢˜ï¼**

### ğŸ“Œ åŸå› ï¼š

- `easy-rag` é»˜è®¤ä½¿ç”¨çš„æ˜¯ `HuggingFaceTokenCountEstimator`ï¼ˆå³ BERT tokenizerï¼‰
- ä½ å®é™…ç”¨çš„é˜¿é‡Œç™¾ç‚¼çš„ `text-embedding-v3` embedding æ¨¡å‹ï¼Œæ˜¯ **DashScope å¹³å°ä¸“ç”¨ tokenizer**ï¼Œé‡‡ç”¨çš„æ˜¯ **SentencePiece å˜ä½“ + æ‹¼éŸ³æ–­å­—ç­–ç•¥**ï¼ˆå’Œ HuggingFace å®Œå…¨ä¸å…¼å®¹ï¼‰

### æ‰€ä»¥ä¼šå‡ºç°çš„æƒ…å†µæ˜¯ï¼š

| é—®é¢˜                           | åæœ                                                         |
| ------------------------------ | ------------------------------------------------------------ |
| tokenizer ä¼°çš„é•¿åº¦æ¯”å®é™…çŸ­     | è¶…å‡º embedding æ¨¡å‹æœ€å¤§ token é™åˆ¶ â†’ æŠ›å¼‚å¸¸æˆ– silently truncate |
| åˆ‡ç‰‡åœ¨é€»è¾‘ä¸Šæ˜¯â€œè¯»å¾—é€šâ€çš„ä¸€æ®µè¯ | å®é™…å–‚ç»™ embedding æ—¶è¢«é”™åˆ‡ â†’ è¯­ä¹‰ä¸¢å¤±                       |
| embedding å‘é‡æ„å»ºæ—¶ä¸å®Œæ•´     | å¬å›å¤±è´¥ã€åŒ¹é…è¯¯å·®å·¨å¤§                                       |
| å¤šè½®å¯¹è¯/å›æ˜¾æ— æ³•å®šä½ç‰‡æ®µ      | æ¨¡å‹å¯èƒ½â€œè®¤ä¸å‡ºâ€è¿™æ®µå†…å®¹                                     |

## â“2. é˜¿é‡Œç™¾ç‚¼ `text-embedding-v3` æ¨¡å‹ï¼Œå¦‚æœä½ ç”¨é»˜è®¤ tokenizerï¼Œä¼šä¸ä¼šâ€œè¯†åˆ«å¤±è´¥â€ï¼Ÿ

### âœ… ä¸¥æ ¼æ¥è¯´ï¼š

> æ¨¡å‹**ä¸æ˜¯â€œè¯†åˆ«å¤±è´¥â€ï¼Œè€Œæ˜¯ä½ é€è¿›å»çš„ token æ•°ç»„æ ¹æœ¬ä¸æ˜¯ä½ ä»¥ä¸ºçš„å¥å­è¯­ä¹‰**ï¼Œå¯¼è‡´å‘é‡è¡¨è¾¾é”™è¯¯ã€‚

ä¾‹å¦‚ï¼š

- ä½ åˆ‡äº†ä¸€æ®µï¼š

  ```
  å¤åˆ¶ç¼–è¾‘
  ç”¨æˆ·æ‚¨å¥½ï¼Œæ¬¢è¿é¢„çº¦çœ¼ç§‘é—¨è¯Šï¼Œæˆ‘ä»¬å°†åœ¨æ˜å¤©ä¸Šåˆä¸ºæ‚¨å®‰æ’åŒ»ç”Ÿã€‚
  ```

- ä½ ç”¨ HuggingFace tokenizer åˆ¤æ–­è¿™æ®µ 180 tokensï¼Œok äº†ï¼›

- å®é™…ç™¾ç‚¼ tokenizer æŠŠå®ƒåˆ†æˆäº† 350 tokensï¼›

- embedding æ¨¡å‹æœ€å¤šåªæ¥æ”¶ 300 tokensï¼Œäºæ˜¯æˆªæ–­äº†ï¼›

- æœ€åå˜æˆåŠæ®µè¯­å¥è¢« embeddingï¼Œè¯­ä¹‰å¯¹ä¸ä¸Šï¼Œå‘é‡å¬å›å¤±è´¥ã€‚

è¿™ä¸æ˜¯â€œä¸èƒ½è¯†åˆ«â€ï¼Œæ˜¯â€œè¯†åˆ«äº†ï¼Œä½†è¯†åˆ«çš„æ˜¯é”™çš„ä¸œè¥¿â€ã€‚

------

## â“3. ä½ é—®ï¼šæ–‡æ¡£è¢« splitter æ‹†æˆæ®µåï¼Œè¿˜è¦å†æ¬¡ç»è¿‡ tokenizer åˆ†æˆ token å—ï¼Ÿ

âœ… **æ˜¯çš„ï¼Œå¿…é¡»å†è¿‡ä¸€é tokenizerï¼**

### ğŸ“Œ ä¸ºä»€ä¹ˆï¼Ÿ

å› ä¸º `Splitter` æ˜¯åŸºäºâ€œtoken ä¼°ç®—â€æ¥åˆ‡çš„ â€”â€” å®ƒç”¨ `TokenCountEstimator` æ¥é¢„ä¼° token æ•°ï¼ˆä¸æ˜¯å®é™…åˆ‡ï¼‰ï¼Œç›®çš„æ˜¯æ§åˆ¶ä¸Šä¸‹æ–‡ token é•¿åº¦ã€‚

ä½†æ˜¯å®é™… embedding é˜¶æ®µï¼š

- è¿˜ä¼šå†ç”¨ **çœŸå® embedding æ¨¡å‹çš„ tokenizer** æŠŠæ–‡æœ¬åˆ†æˆçœŸæ­£çš„ token åºåˆ—
- ç„¶åé€ç»™æ¨¡å‹åš embeddingï¼ˆå‘é‡åŒ–ï¼‰

## âš ï¸ é‚£ä½ æœ€åä¸€ä¸ªæ‹…å¿ƒæ˜¯å¯¹çš„ï¼š

> å¦‚æœä½ ç”¨é”™äº† tokenizer å»åˆ‡ç‰‡ï¼Œ**é‚£å°±å¾ˆå¯èƒ½åˆ‡åœ¨ä¸€ä¸ªçœŸå® token ä¸­é—´**ã€‚

æ¯”å¦‚ä½ åŸä»¥ä¸ºè¿™æ˜¯ 200 tokensï¼Œä½†çœŸå® tokenizer ä¸€çœ‹å®ƒæ˜¯ 350 tokensï¼Œåˆ‡åœ¨ token ä¸­é—´äº†ï¼Œå°±é€ æˆï¼š

- æ¨¡å‹è§£æå¤±è´¥æˆ–è¯­ä¹‰é”™è¯¯ï¼›
- embedding å‘é‡åç§»ï¼›
- æ— æ³•å¬å›åŸæ–‡æ®µã€‚

## âœ… æ­£ç¡®å§¿åŠ¿ï¼šå¦‚ä½•é¿å…è¿™ç§ç‹—è¡€é”™ä½ï¼Ÿ

ä½ å¿…é¡»**ä½¿ç”¨çœŸå® embedding æ¨¡å‹é…å¥—çš„ tokenizer æ¥åš token count estimator**ï¼Œæ¯”å¦‚é˜¿é‡Œç™¾ç‚¼ï¼š

```java
TokenCountEstimator estimator = DashScopeTokenCountEstimator.create();

DocumentSplitter splitter = TokenTextSplitter.builder()
    .tokenCountEstimator(estimator)
    .maxTokens(300)  // ç™¾ç‚¼ embedding æ¨¡å‹æœ€å¤§ tokens
    .build();
```

LangChain4j å·²å†…ç½® `DashScopeTokenCountEstimator`ï¼Œå¯ä»¥ç›´æ¥ç”¨ã€‚

## âœ… æœ€ç»ˆæ€»ç»“ï¼š

| é—®é¢˜                                        | æ­£ç¡®ç»“è®º                                                     |
| ------------------------------------------- | ------------------------------------------------------------ |
| `easy-rag` é»˜è®¤ tokenizer å®‰å…¨å—ï¼Ÿ          | âŒ ä»…å¯¹ HuggingFace æ¨¡å‹å®‰å…¨ï¼Œç”¨å…¶ä»–æ¨¡å‹å¿…é¡»æ‰‹åŠ¨æŒ‡å®š          |
| tokenizer é”™è¯¯ä¼šå¯¼è‡´å•¥ï¼Ÿ                    | token é•¿åº¦åˆ¤æ–­é”™è¯¯ã€è¯­ä¹‰é”™åˆ‡ã€embedding è¯¯å‘é‡ã€å¬å›å¤±è´¥     |
| æ–‡æ¡£ splitter æ‹†æ®µåè¿˜ä¼šè¢« tokenizer åˆ†å—ï¼Ÿ | âœ… æ˜¯çš„ï¼Œembedding å‰ä¸€å®šå†æ¬¡ tokenizer                       |
| ä¼šä¸ä¼šåˆ‡åœ¨ token ä¸­é—´ï¼Ÿ                     | âŒ ä¼šçš„ï¼Œå¦‚æœ tokenizer ä¸åŒ¹é…ï¼Œå°±ä¼šåˆ‡å¾—å››ä¸åƒ                |
| æ€ä¹ˆåŠï¼Ÿ                                    | å¿…é¡»ç”¨ä¸ä½  embedding æ¨¡å‹ä¸€è‡´çš„ TokenCountEstimatorï¼ˆå¦‚ DashScope ä¸“ç”¨ï¼‰ |



## âœ… æœ€é‡è¦çš„ç­”æ¡ˆï¼ˆå…ˆè¯´ç»“è®ºï¼‰ï¼š

> **Embedding æ¨¡å‹é€šå¸¸æ˜¯è‡ªå¸¦ tokenizer çš„**ï¼Œ
>  ä½ è‡ªå·±ä¼ è¿›å»çš„ tokenizerï¼ˆå¦‚ç”¨äº `TokenCountEstimator`ï¼‰åªæ˜¯**ä¸ºäº†æå‰ä¼°ç®— token æ•°é‡ï¼Œé¿å…è¶…è¿‡ä¸Šé™ï¼Œä¸æ˜¯é€ç»™æ¨¡å‹ç”¨çš„ tokenizerï¼**

------

### âš ï¸ æ‰€ä»¥æ³¨æ„ä¸¤è€…çš„åŒºåˆ«ï¼š

| åœºæ™¯                                                       | Tokenizer ç”¨æ¥å¹²å˜›ï¼Ÿ                                         | æ˜¯å¦å½±å“æ¨¡å‹æœ¬èº«ï¼Ÿ       |
| ---------------------------------------------------------- | ------------------------------------------------------------ | ------------------------ |
| **ä½ è‡ªå·±ä¼ è¿›å»çš„ tokenizer**ï¼ˆç”¨äº `TokenCountEstimator`ï¼‰ | æ˜¯ç”¨æ¥ã€Œä¼°è®¡ã€å­—ç¬¦ä¸²å˜æˆå¤šå°‘ tokenï¼Œå¥½æ‹†åˆ†æ–‡æ¡£ç”¨çš„           | âŒ ä¸å½±å“æ¨¡å‹å‘é‡åŒ–è¡Œä¸º   |
| **Embedding æ¨¡å‹å†…éƒ¨è‡ªå¸¦çš„ tokenizer**                     | çœŸæ­£ç”¨äºã€Œå°† TextSegment.text è½¬æˆ token idsã€ï¼Œä¾›åº•å±‚æ¨¡å‹åƒ | âœ… å†³å®šäº†æœ€ç»ˆå‘é‡ç”Ÿæˆç»“æœ |



# TextSegmentæ˜¯æ€ä¹ˆæ¥çš„ï¼Ÿï¼Ÿ

## ğŸ§  é‚£å®ƒå’Œ tokenizer æœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿ

### ğŸš« `TextSegment` æœ¬èº« **ä¸è´Ÿè´£è°ƒç”¨ tokenizer**

å®ƒå°±æ˜¯ä¸ª â€œè£…å†…å®¹çš„å°ç›’å­â€ã€‚

ä½†ä½ æ„å»º `TextSegment` çš„æ—¶å€™ï¼ˆé€šè¿‡ `Splitter`ï¼‰ï¼Œå†…éƒ¨ä¼šç”¨ `TokenCountEstimator` æ¥è¯„ä¼°ï¼š

- æ¯ä¸€æ®µå¤šå°‘ tokenï¼Ÿ
- æœ‰æ²¡æœ‰è¶…å‡º token é™åˆ¶ï¼Ÿ
- æ˜¯å¦éœ€è¦ç»§ç»­æ‹†åˆ†ï¼Ÿ

æ‰€ä»¥ä½ è¯´çš„è¿™ä¸ªç†è§£ï¼š

> â€œé»˜è®¤å°†ä¼ å…¥çš„è¿›å»çš„Stringç”¨tokenizeræä¸€ä¸‹å—ï¼Ÿâ€

âœ… **å‡†ç¡®åœ°è¯´ï¼š**

- #### æ˜¯é€šè¿‡ **Splitter + TokenCountEstimator** æçš„ï¼Œä¸æ˜¯ `TextSegment` è‡ªå·±ã€‚

- #### `TextSegment` åªæ˜¯ç»“æ„åŒ–è¡¨è¾¾å‡ºæ¥çš„æ‹†åˆ†ç»“æœï¼ˆtext + metadataï¼‰ã€‚





